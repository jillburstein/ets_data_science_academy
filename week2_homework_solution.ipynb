{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON -> DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the `JSON` structure to a `DataFrame`, we have to flatten it. Here we decided that\n",
    "rows will be events. Thus columns should contain all metadata about the examinee that\n",
    "generated the event (in database `SQL`, this is known as a \"denormalized view\" of the data).\n",
    "On the up side, everything is based on events, which is simple. On the down side, we are\n",
    "duplicating the examinee's info across all of her events.\n",
    "\n",
    "Thus the transformed data will look like this:\n",
    "\n",
    "```\n",
    "Row 0: test session 0, event 0\n",
    "Row 1: test session 0, event 1\n",
    "...\n",
    "Row n-1: test session 0, event n-1\n",
    "Row n: test session 1, event 0\n",
    "...\n",
    "\n",
    "Each row represents: event of some examinee\n",
    "Columns: {all examinee_attributes} followed by {all event_attributes}\n",
    "```\n",
    "\n",
    "Notes:\n",
    "* In this data we happen to have only a single test session.\n",
    "* Looks like there are two types of events: \"interactions\" and \"events\". Each one will have its own row.\n",
    "\n",
    "What's hard to explain in words is easy when you print the resulting `DataFrame` and look at some of its rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a dictionary.\n",
    "\n",
    "# Remember to use the 'with' clause around file access code. Keep the code inside the 'with'\n",
    "# as small as possible, as it is good practice to relinquish resource holds as soon as you\n",
    "# don't need them any more (they are fragile and may be needed/overwritten by other programs).\n",
    "with open(\"homework_week2_json_parsing.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to modularize your code into small functions whenever possible. Don't put\n",
    "# everything in one big loop that's hard to understand, debug and maintain!\n",
    "\n",
    "# Global variables available to get_flattened_events() since they are defined outside\n",
    "# its scope.\n",
    "interaction_columns = [\"interactionId\", \"interactionType\", \"value\", \"time\"]\n",
    "event_columns = [\"type\", \"action\", \"time\", \"itemId\", \"from\", \"to\"]\n",
    "all_event_columns = [\"event_type\"] + interaction_columns + event_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened_events(heartbeat):\n",
    "    \"\"\"Returns a list of rows (not in a DataFrame, just a list) of interactions and events\n",
    "    of an examinee's heartbeat field.\"\"\"\n",
    "    \n",
    "    # Flatten the heartbeat fields into a list.\n",
    "    heartbeats = [(k, v) for k, v in heartbeat.items() if k != \"events\" and k != \"interactions\"]\n",
    "\n",
    "    # Flatten the interactions into a list.\n",
    "    interactions = [(interaction_id, key, interaction[key]) \n",
    "         for interaction_id, interaction in enumerate(heartbeat[\"interactions\"]) \n",
    "         for key in interaction_columns]\n",
    "\n",
    "    # Flatten events.\n",
    "    events = [(event[\"type\"], event[\"action\"], event[\"time\"], event[\"itemId\"],\n",
    "               event[\"value\"][\"from\"] if \"value\" in event else None,\n",
    "               event[\"value\"][\"to\"] if \"value\" in event else None)\n",
    "               for event in heartbeat[\"events\"]]\n",
    "\n",
    "    # Prepend an event type column that's either \"interaction\" or \"event\". This is how I\n",
    "    # interpreted putting the data into a DataFrame, but this can be done in other ways too.\n",
    "    # This is basically a left-join: fill in all event columns of interaction rows with nulls,\n",
    "    # and all interaction columns of event rows with nulls.\n",
    "    all_event_data = [(\"interaction\", ) + interaction +\n",
    "                      tuple(len(event_columns) * [None]) \n",
    "                      for interaction in interactions] + \\\n",
    "    [(\"event\", ) + tuple(len(interaction_columns) * [None]) + event for event in events]\n",
    "    return all_event_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test this part of the code first. Find all events of session 0.\n",
    "all_events_example = get_flattened_events(data['TestSessions'][0]['HeartBeats'][0])\n",
    "\n",
    "# Some interaction events.\n",
    "print(all_events_example[:3])\n",
    "\n",
    "# Now show some \"event-events\" from the above table.\n",
    "print(all_events_example[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the metadata of each test session and examinee.\n",
    "# Remember - vectorized expressions are more readable and often faster in Python than loops, \n",
    "# to use them when you can.\n",
    "\n",
    "# Instead of hard-coding those, just read column names from the first examinee's dictionary\n",
    "# except the heartbeat field.\n",
    "examinee_columns = [field for field in data['TestSessions'][0].keys() \n",
    "                    if field != \"HeartBeats\"]\n",
    "\n",
    "def get_examinee_info(session):\n",
    "    \"\"\"Returns examinee metadata for a certain session.\"\"\"\n",
    "    # The values corresponding to 'examinee_columns'. Note that items() returns them in a\n",
    "    # deterministic order, so we can rely on their matching.\n",
    "    return tuple(value \n",
    "                 for field, value in data['TestSessions'][0].items() \n",
    "                 if field != \"HeartBeats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test only this part of the code.\n",
    "print(get_examinee_info(data['TestSessions'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate the cross-product of examinees and events.\n",
    "\n",
    "def get_examinee_event_data_frame(data):\n",
    "    \"\"\"Returns a DataFrame whose rows are events, for each examinee and interaction/event\n",
    "    entry in the JSON data.\n",
    "    \n",
    "    Adds a column with the session number (a counter starting at 0 for all sessions in the\n",
    "    JSON data).\n",
    "    \n",
    "    Assumes a single HeartBeats field per session.\"\"\"\n",
    "\n",
    "    all_columns = [\"session_id\"] + examinee_columns + all_event_columns\n",
    "    \n",
    "    # Note: this runs over the entire data only once, which is ideally what we want to do,\n",
    "    # especially if the data is being streamed.\n",
    "    df = pd.DataFrame(\n",
    "        [(session_id,) + get_examinee_info(session) + event\n",
    "         for session_id, session in enumerate(data['TestSessions'])\n",
    "         for event in get_flattened_events(session['HeartBeats'][0])],\n",
    "        columns = all_columns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_examinee_event_data_frame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example query. Doesn't make a lot of sense here but just to see what's possible.\n",
    "df.groupby('ExamineeIdentifier').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML -> DataFrame\n",
    "This follows the same idea. We do a simple example of extracting test event timestamps for each customer.\n",
    "\n",
    "We use an interesting idea here: traversing the entire XML tree with a recursive call. When we arrive at a node of interest, we emit it (with the \"yield\" keywords; we learned about generator expressions - this is how you write one. Every time \"yield\" is called, an element is emitted when the function is called).\n",
    "\n",
    "Then, we go back up the hierarchy for each such node of interest (say, an event node), and extract the customer information corresponding to it from elsewhere in the hierarchy. W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('homework_week2_xml_parsing.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Helper functions.\"\"\"\n",
    "def unqualified_tag_name(tag):\n",
    "    return tag.split(\"}\")[1]\n",
    "\n",
    "def first_child_with_name(node, child_name):\n",
    "    return next(child for child in node\n",
    "                if unqualified_tag_name(child.tag) == child_name)\n",
    "\n",
    "def get_nested_element_data(element):\n",
    "    return [(unqualified_tag_name(c.tag), c.text.strip() if c.text else \"\") \n",
    "            for c in element if c.text and len(c.text.strip()) > 0]\n",
    "\n",
    "\"\"\"Traverses the entire XML tree and generates elements that have actual\n",
    "fields in them (i.e., leaves of the tree). For each node, we output\n",
    "1) The breadcrumb hierarchy (all its ancestors, starting with the root\n",
    "node); 2) its nested field names and values.\n",
    "\n",
    "Refer to the python manual to learn more about the yield keyword, which\n",
    "is how to emit elements from a function that returns a generator expression,\n",
    "like the one below.\"\"\"\n",
    "\n",
    "\n",
    "def traverse_xml_tree(root):\n",
    "    \"\"\"Top-level call.\"\"\"\n",
    "    for value in _traverse_xml_tree(root, []):\n",
    "        yield value\n",
    "\n",
    "def _traverse_xml_tree(element, stack):\n",
    "    \"\"\"Recursive call. We pass the stack when traversing children, tacking\n",
    "    on the current node.\"\"\"\n",
    "    stack.append(element)\n",
    "    fields = get_nested_element_data(element)\n",
    "    if fields:\n",
    "        # Stack must be deep-copied, since it is a changing list throughout\n",
    "        # the recursion.\n",
    "        yield stack.copy(), fields\n",
    "    for child in element:\n",
    "        for value in _traverse_xml_tree(child, stack):\n",
    "            yield value\n",
    "    stack.pop()\n",
    "    \n",
    "def get_customer_name(record):\n",
    "    \"\"\"Walks down the hierarchy from the root of the current record\n",
    "    and returns the customer first and last name that appear in nested\n",
    "    tags under the root.\"\"\"\n",
    "    event_data = first_child_with_name(record[0][0], \"CustomerResultData\")\n",
    "    customer_name = first_child_with_name(event_data, \"CustomerName\")\n",
    "    return [customer_name[0].text, customer_name[1].text]\n",
    "\n",
    "def extract_time_session_events(root):\n",
    "    \"\"\"The main parsing call. Joins the customer and test data.\"\"\"\n",
    "    records = [entry for entry in traverse_xml_tree(root) if \n",
    "         [unqualified_tag_name(parent.tag) for parent in entry[0]] ==\n",
    "         ['CustomerRecord', 'CustomerEventData', 'TestSessionEvent']]\n",
    "\n",
    "    columns = ['FirstName', 'LastName', 'SequenceNo', 'TimeStamp', 'TestComponentCode', 'DetailText']\n",
    "    data = [get_customer_name(record) +  [value for key, value in record[1]] for record in records]\n",
    "    return pd.DataFrame(data, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>SequenceNo</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>TestComponentCode</th>\n",
       "      <th>DetailText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85c24d74e0f90af</td>\n",
       "      <td>d79ee6182f3bd06</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-13T10:01:19.716+02:00</td>\n",
       "      <td>TELXMLUNF00011000PKG001</td>\n",
       "      <td>Candidate starts the test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85c24d74e0f90af</td>\n",
       "      <td>d79ee6182f3bd06</td>\n",
       "      <td>884</td>\n",
       "      <td>2019-04-13T13:49:11.097+02:00</td>\n",
       "      <td>TELXMLUNF00011000PKG001</td>\n",
       "      <td>Candidate completes the test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FirstName         LastName SequenceNo                      TimeStamp  \\\n",
       "0  85c24d74e0f90af  d79ee6182f3bd06          1  2019-04-13T10:01:19.716+02:00   \n",
       "1  85c24d74e0f90af  d79ee6182f3bd06        884  2019-04-13T13:49:11.097+02:00   \n",
       "\n",
       "         TestComponentCode                    DetailText  \n",
       "0  TELXMLUNF00011000PKG001     Candidate starts the test  \n",
       "1  TELXMLUNF00011000PKG001  Candidate completes the test  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_time_session_events(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, one could parse different parts of the file (e.g., TestEvents). This would be done similarly."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
